{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D, Reshape\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image\n",
    "import time\n",
    "import os\n",
    "import argparse\n",
    "import json\n",
    "\n",
    "k.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cropping because images contained timestamps\n",
    "\n",
    "# for folders in os.listdir('ck/img_divided'):\n",
    "#     for file in os.listdir('ck/img_divided/'+folders):\n",
    "#         img_arr=np.array(Image.open('ck/img_divided/'+folders+'/'+file))[12:-60]\n",
    "#         img=Image.fromarray(img_arr).save('Ck/img_divided2/'+folders+'/'+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 180\n",
    "nb_classes = 8\n",
    "batch_size = 16\n",
    "\n",
    "inputs={}\n",
    "inputs['vgg']=[224, 224]\n",
    "inputs['xception']=[299, 299]\n",
    "inputs['mobilenet']=[224, 224]\n",
    "\n",
    "classes_onehot = np.eye(8)\n",
    "learn_rate = 1e-4  # sgd learning rate\n",
    "momentum = .9  # sgd momentum to avoid local minimum\n",
    "transformation_ratio = .15  # how aggressive will be the data augmentation/transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xception=applications.xception.Xception(include_top=False, weights='imagenet')\n",
    "# vgg=applications.vgg16.VGG16(include_top=False, weights='imagenet')\n",
    "# mobilenet=applications.mobilenet.MobileNet(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(size, filename):\n",
    "    img_array = []\n",
    "    label_array = []\n",
    "    with open('ck/archive/image_mapping.json') as ma:\n",
    "        img_map = json.load(ma)\n",
    "    for file in os.listdir('ck/' + filename):\n",
    "        img=Image.open('ck/' + filename + '/' + file).convert('RGB')\n",
    "        img_array.append(np.array(img).reshape(size[0], size[1], 3))\n",
    "        label = img_map[file.split('.')[0]]['number']\n",
    "        label_onehot = classes_onehot[label]\n",
    "        label_array.append(label_onehot)\n",
    "    \n",
    "    return np.array(img_array), np.array(label_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name):\n",
    "    if model_name == 'xception':\n",
    "        xception=applications.xception.Xception(include_top=False, weights='imagenet')        \n",
    "        x = xception.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(512, activation='relu') (x)\n",
    "        predictions = Dense(nb_classes, activation='softmax')(x)    \n",
    "        model=Model(xception.input, predictions)\n",
    "        \n",
    "        for layer in xception.layers:\n",
    "            layer.trainable = False        \n",
    "    elif model_name == 'mobilenet':\n",
    "        mnet = applications.mobilenet.MobileNet(include_top=False, weights='imagenet')\n",
    "        x = mnet.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Reshape((none, 1, 1, 1024)) (x)\n",
    "        x = Dropout() (x)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=load_dataset(size = inputs['xception'], filename = 'img-xception')\n",
    "x_train, x_validation,y_train, y_validation = train_test_split(x, y, test_size = 0.10, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=get_model('xception')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_x_validation = applications.xception.preprocess_input(x_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=applications.xception.preprocess_input,\n",
    "                                       rotation_range=0.35,\n",
    "                                       shear_range=transformation_ratio,\n",
    "                                       zoom_range=transformation_ratio,\n",
    "                                       cval=transformation_ratio,\n",
    "                                       horizontal_flip=True)\n",
    "\n",
    "# validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "# x_validation = x_validation/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow(x_train, y_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# validation_generator = validation_datagen.flow(x_validation, y_validation, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir='logs-xception/{}'.format(time.time()), histogram_freq=1,\n",
    "                          write_graph=True, write_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.SGD(lr=learn_rate,decay=1e-6, momentum=momentum, nesterov=True), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"weights-prolonged/improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vibhu\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  after removing the cwd from sys.path.\n",
      "c:\\users\\vibhu\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., callbacks=[<keras.ca..., epochs=300)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "63/63 [==============================] - 119s 2s/step - loss: 2.0445 - acc: 0.1629 - val_loss: 2.0206 - val_acc: 0.2143\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.21429, saving model to weights-prolonged/improvement-01-0.21.hdf5\n",
      "Epoch 2/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.9801 - acc: 0.2347 - val_loss: 1.9866 - val_acc: 0.2500\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.21429 to 0.25000, saving model to weights-prolonged/improvement-02-0.25.hdf5\n",
      "Epoch 3/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.9457 - acc: 0.2433 - val_loss: 1.9661 - val_acc: 0.2679\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.25000 to 0.26786, saving model to weights-prolonged/improvement-03-0.27.hdf5\n",
      "Epoch 4/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.9253 - acc: 0.2461 - val_loss: 1.9502 - val_acc: 0.2857\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.26786 to 0.28571, saving model to weights-prolonged/improvement-04-0.29.hdf5\n",
      "Epoch 5/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.9006 - acc: 0.2712 - val_loss: 1.9414 - val_acc: 0.3214\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.28571 to 0.32143, saving model to weights-prolonged/improvement-05-0.32.hdf5\n",
      "Epoch 6/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.8871 - acc: 0.2732 - val_loss: 1.9320 - val_acc: 0.3125\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.32143\n",
      "Epoch 7/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.8682 - acc: 0.2988 - val_loss: 1.9259 - val_acc: 0.3214\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.32143\n",
      "Epoch 8/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.8512 - acc: 0.3197 - val_loss: 1.9189 - val_acc: 0.3393\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.32143 to 0.33929, saving model to weights-prolonged/improvement-08-0.34.hdf5\n",
      "Epoch 9/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.8373 - acc: 0.3389 - val_loss: 1.9120 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.33929 to 0.34821, saving model to weights-prolonged/improvement-09-0.35.hdf5\n",
      "Epoch 10/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.8261 - acc: 0.3528 - val_loss: 1.9072 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.34821 to 0.35714, saving model to weights-prolonged/improvement-10-0.36.hdf5\n",
      "Epoch 11/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.8047 - acc: 0.3601 - val_loss: 1.9008 - val_acc: 0.3393\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.35714\n",
      "Epoch 12/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.7915 - acc: 0.3760 - val_loss: 1.8964 - val_acc: 0.3393\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.35714\n",
      "Epoch 13/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.7788 - acc: 0.4012 - val_loss: 1.8896 - val_acc: 0.3393\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.35714\n",
      "Epoch 14/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.7630 - acc: 0.3937 - val_loss: 1.8855 - val_acc: 0.3661\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.35714 to 0.36607, saving model to weights-prolonged/improvement-14-0.37.hdf5\n",
      "Epoch 15/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.7559 - acc: 0.3966 - val_loss: 1.8803 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.36607 to 0.37500, saving model to weights-prolonged/improvement-15-0.38.hdf5\n",
      "Epoch 16/300\n",
      "63/63 [==============================] - 100s 2s/step - loss: 1.7215 - acc: 0.4032 - val_loss: 1.8749 - val_acc: 0.3839\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.37500 to 0.38393, saving model to weights-prolonged/improvement-16-0.38.hdf5\n",
      "Epoch 17/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.7202 - acc: 0.4154 - val_loss: 1.8714 - val_acc: 0.3839\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.38393\n",
      "Epoch 18/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.7057 - acc: 0.4488 - val_loss: 1.8668 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.38393\n",
      "Epoch 19/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.6959 - acc: 0.4381 - val_loss: 1.8619 - val_acc: 0.3929\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.38393 to 0.39286, saving model to weights-prolonged/improvement-19-0.39.hdf5\n",
      "Epoch 20/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.6822 - acc: 0.4457 - val_loss: 1.8583 - val_acc: 0.3929\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.39286\n",
      "Epoch 21/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.6687 - acc: 0.4633 - val_loss: 1.8540 - val_acc: 0.4018\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.39286 to 0.40179, saving model to weights-prolonged/improvement-21-0.40.hdf5\n",
      "Epoch 22/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.6688 - acc: 0.4496 - val_loss: 1.8524 - val_acc: 0.3929\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.40179\n",
      "Epoch 23/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.6406 - acc: 0.4746 - val_loss: 1.8484 - val_acc: 0.3929\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.40179\n",
      "Epoch 24/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.6350 - acc: 0.4691 - val_loss: 1.8432 - val_acc: 0.3929\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.40179\n",
      "Epoch 25/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.6168 - acc: 0.4873 - val_loss: 1.8366 - val_acc: 0.4018\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.40179\n",
      "Epoch 26/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.6008 - acc: 0.4921 - val_loss: 1.8337 - val_acc: 0.3929\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.40179\n",
      "Epoch 27/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.5962 - acc: 0.4760 - val_loss: 1.8322 - val_acc: 0.3839\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.40179\n",
      "Epoch 28/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.5794 - acc: 0.4936 - val_loss: 1.8275 - val_acc: 0.3929\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.40179\n",
      "Epoch 29/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.5706 - acc: 0.4970 - val_loss: 1.8251 - val_acc: 0.3929\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.40179\n",
      "Epoch 30/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.5613 - acc: 0.5170 - val_loss: 1.8219 - val_acc: 0.3839\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.40179\n",
      "Epoch 31/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.5539 - acc: 0.5111 - val_loss: 1.8180 - val_acc: 0.3839\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.40179\n",
      "Epoch 32/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.5379 - acc: 0.5234 - val_loss: 1.8157 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.40179\n",
      "Epoch 33/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.5130 - acc: 0.5312 - val_loss: 1.8150 - val_acc: 0.3661\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.40179\n",
      "Epoch 34/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.5198 - acc: 0.5169 - val_loss: 1.8097 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.40179\n",
      "Epoch 35/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.5043 - acc: 0.5365 - val_loss: 1.8052 - val_acc: 0.3839\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.40179\n",
      "Epoch 36/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.4880 - acc: 0.5451 - val_loss: 1.8031 - val_acc: 0.3661\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.40179\n",
      "Epoch 37/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.4837 - acc: 0.5414 - val_loss: 1.8003 - val_acc: 0.3661\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.40179\n",
      "Epoch 38/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.4860 - acc: 0.5478 - val_loss: 1.8007 - val_acc: 0.3661\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.40179\n",
      "Epoch 39/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.4691 - acc: 0.5424 - val_loss: 1.7974 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.40179\n",
      "Epoch 40/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.4446 - acc: 0.5611 - val_loss: 1.7940 - val_acc: 0.3661\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.40179\n",
      "Epoch 41/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 99s 2s/step - loss: 1.4489 - acc: 0.5566 - val_loss: 1.7874 - val_acc: 0.3661\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.40179\n",
      "Epoch 42/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.4407 - acc: 0.5480 - val_loss: 1.7871 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.40179\n",
      "Epoch 43/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.4294 - acc: 0.5710 - val_loss: 1.7876 - val_acc: 0.3661\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.40179\n",
      "Epoch 44/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.4203 - acc: 0.5758 - val_loss: 1.7843 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.40179\n",
      "Epoch 45/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.4090 - acc: 0.5710 - val_loss: 1.7800 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.40179\n",
      "Epoch 46/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.3942 - acc: 0.5829 - val_loss: 1.7800 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.40179\n",
      "Epoch 47/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.3988 - acc: 0.5804 - val_loss: 1.7760 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.40179\n",
      "Epoch 48/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.3855 - acc: 0.5730 - val_loss: 1.7719 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.40179\n",
      "Epoch 49/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.3793 - acc: 0.5869 - val_loss: 1.7734 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.40179\n",
      "Epoch 50/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.3657 - acc: 0.5804 - val_loss: 1.7700 - val_acc: 0.3661\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.40179\n",
      "Epoch 51/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.3942 - acc: 0.5522 - val_loss: 1.7690 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.40179\n",
      "Epoch 52/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.3511 - acc: 0.5808 - val_loss: 1.7690 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.40179\n",
      "Epoch 53/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.3418 - acc: 0.5853 - val_loss: 1.7601 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.40179\n",
      "Epoch 54/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.3508 - acc: 0.5863 - val_loss: 1.7617 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.40179\n",
      "Epoch 55/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.3461 - acc: 0.5760 - val_loss: 1.7633 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.40179\n",
      "Epoch 56/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.3219 - acc: 0.5947 - val_loss: 1.7588 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.40179\n",
      "Epoch 57/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.2966 - acc: 0.6097 - val_loss: 1.7597 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.40179\n",
      "Epoch 58/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.3273 - acc: 0.5812 - val_loss: 1.7542 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.40179\n",
      "Epoch 59/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.2985 - acc: 0.6004 - val_loss: 1.7539 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.40179\n",
      "Epoch 60/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.2821 - acc: 0.5984 - val_loss: 1.7486 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.40179\n",
      "Epoch 61/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.2832 - acc: 0.6036 - val_loss: 1.7522 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.40179\n",
      "Epoch 62/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.2809 - acc: 0.6137 - val_loss: 1.7451 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.40179\n",
      "Epoch 63/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.2775 - acc: 0.6212 - val_loss: 1.7411 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.40179\n",
      "Epoch 64/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.2697 - acc: 0.6089 - val_loss: 1.7429 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.40179\n",
      "Epoch 65/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.2624 - acc: 0.6137 - val_loss: 1.7410 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.40179\n",
      "Epoch 66/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.2603 - acc: 0.6276 - val_loss: 1.7346 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.40179\n",
      "Epoch 67/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.2412 - acc: 0.6189 - val_loss: 1.7343 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.40179\n",
      "Epoch 68/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.2576 - acc: 0.6095 - val_loss: 1.7330 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.40179\n",
      "Epoch 69/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.2444 - acc: 0.6192 - val_loss: 1.7314 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.40179\n",
      "Epoch 70/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.2441 - acc: 0.6182 - val_loss: 1.7308 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.40179\n",
      "Epoch 71/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.2418 - acc: 0.6202 - val_loss: 1.7303 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.40179\n",
      "Epoch 72/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.2120 - acc: 0.6264 - val_loss: 1.7228 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.40179\n",
      "Epoch 73/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.2113 - acc: 0.6348 - val_loss: 1.7228 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.40179\n",
      "Epoch 74/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.2045 - acc: 0.6377 - val_loss: 1.7226 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.40179\n",
      "Epoch 75/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.2079 - acc: 0.6385 - val_loss: 1.7193 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.40179\n",
      "Epoch 76/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1870 - acc: 0.6486 - val_loss: 1.7168 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.40179\n",
      "Epoch 77/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.2056 - acc: 0.6444 - val_loss: 1.7120 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.40179\n",
      "Epoch 78/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1985 - acc: 0.6377 - val_loss: 1.7075 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.40179\n",
      "Epoch 79/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1887 - acc: 0.6298 - val_loss: 1.7066 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.40179\n",
      "Epoch 80/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1851 - acc: 0.6320 - val_loss: 1.7086 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.40179\n",
      "Epoch 81/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1721 - acc: 0.6411 - val_loss: 1.7078 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.40179\n",
      "Epoch 82/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1633 - acc: 0.6349 - val_loss: 1.7020 - val_acc: 0.3661\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.40179\n",
      "Epoch 83/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1727 - acc: 0.6528 - val_loss: 1.7028 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.40179\n",
      "Epoch 84/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1593 - acc: 0.6361 - val_loss: 1.7006 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.40179\n",
      "Epoch 85/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1475 - acc: 0.6532 - val_loss: 1.7004 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.40179\n",
      "Epoch 86/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 99s 2s/step - loss: 1.1465 - acc: 0.6548 - val_loss: 1.6948 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.40179\n",
      "Epoch 87/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1673 - acc: 0.6266 - val_loss: 1.6917 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.40179\n",
      "Epoch 88/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1530 - acc: 0.6393 - val_loss: 1.6941 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.40179\n",
      "Epoch 89/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1440 - acc: 0.6480 - val_loss: 1.6937 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.40179\n",
      "Epoch 90/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1392 - acc: 0.6506 - val_loss: 1.6898 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.40179\n",
      "Epoch 91/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1236 - acc: 0.6603 - val_loss: 1.6864 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.40179\n",
      "Epoch 92/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1240 - acc: 0.6484 - val_loss: 1.6878 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.40179\n",
      "Epoch 93/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1283 - acc: 0.6538 - val_loss: 1.6827 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.40179\n",
      "Epoch 94/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1221 - acc: 0.6564 - val_loss: 1.6808 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.40179\n",
      "Epoch 95/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1144 - acc: 0.6736 - val_loss: 1.6798 - val_acc: 0.3661\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.40179\n",
      "Epoch 96/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0961 - acc: 0.6488 - val_loss: 1.6854 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.40179\n",
      "Epoch 97/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1017 - acc: 0.6698 - val_loss: 1.6774 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.40179\n",
      "Epoch 98/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0981 - acc: 0.6726 - val_loss: 1.6775 - val_acc: 0.3661\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.40179\n",
      "Epoch 99/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0823 - acc: 0.6665 - val_loss: 1.6761 - val_acc: 0.3661\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.40179\n",
      "Epoch 100/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0920 - acc: 0.6653 - val_loss: 1.6703 - val_acc: 0.3661\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.40179\n",
      "Epoch 101/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0711 - acc: 0.6816 - val_loss: 1.6673 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.40179\n",
      "Epoch 102/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0828 - acc: 0.6506 - val_loss: 1.6772 - val_acc: 0.3661\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.40179\n",
      "Epoch 103/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0847 - acc: 0.6734 - val_loss: 1.6739 - val_acc: 0.3661\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.40179\n",
      "Epoch 104/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0844 - acc: 0.6702 - val_loss: 1.6644 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.40179\n",
      "Epoch 105/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0576 - acc: 0.6871 - val_loss: 1.6685 - val_acc: 0.3661\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.40179\n",
      "Epoch 106/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0753 - acc: 0.6796 - val_loss: 1.6626 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.40179\n",
      "Epoch 107/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0814 - acc: 0.6596 - val_loss: 1.6691 - val_acc: 0.3661\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.40179\n",
      "Epoch 108/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0371 - acc: 0.6827 - val_loss: 1.6623 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.40179\n",
      "Epoch 109/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0465 - acc: 0.6889 - val_loss: 1.6629 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.40179\n",
      "Epoch 110/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0546 - acc: 0.6722 - val_loss: 1.6622 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.40179\n",
      "Epoch 111/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0394 - acc: 0.6851 - val_loss: 1.6573 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.40179\n",
      "Epoch 112/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0447 - acc: 0.6822 - val_loss: 1.6550 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.40179\n",
      "Epoch 113/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0277 - acc: 0.6837 - val_loss: 1.6561 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.40179\n",
      "Epoch 114/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0489 - acc: 0.6633 - val_loss: 1.6619 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.40179\n",
      "Epoch 115/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0208 - acc: 0.6903 - val_loss: 1.6557 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.40179\n",
      "Epoch 116/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0365 - acc: 0.6873 - val_loss: 1.6426 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.40179\n",
      "Epoch 117/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9948 - acc: 0.7131 - val_loss: 1.6476 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.40179\n",
      "Epoch 118/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0346 - acc: 0.6802 - val_loss: 1.6486 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.40179\n",
      "Epoch 119/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0011 - acc: 0.7054 - val_loss: 1.6456 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.40179\n",
      "Epoch 120/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0018 - acc: 0.7046 - val_loss: 1.6505 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.40179\n",
      "Epoch 121/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0045 - acc: 0.6889 - val_loss: 1.6504 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.40179\n",
      "Epoch 122/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9939 - acc: 0.6972 - val_loss: 1.6416 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.40179\n",
      "Epoch 123/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0133 - acc: 0.6966 - val_loss: 1.6395 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.40179\n",
      "Epoch 124/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9845 - acc: 0.6969 - val_loss: 1.6418 - val_acc: 0.3929\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.40179\n",
      "Epoch 125/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9904 - acc: 0.7077 - val_loss: 1.6393 - val_acc: 0.3929\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.40179\n",
      "Epoch 126/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9949 - acc: 0.7071 - val_loss: 1.6450 - val_acc: 0.3929\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.40179\n",
      "Epoch 127/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9724 - acc: 0.7135 - val_loss: 1.6349 - val_acc: 0.3929\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.40179\n",
      "Epoch 128/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9835 - acc: 0.7147 - val_loss: 1.6345 - val_acc: 0.3929\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.40179\n",
      "Epoch 129/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9939 - acc: 0.6950 - val_loss: 1.6404 - val_acc: 0.3929\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.40179\n",
      "Epoch 130/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9829 - acc: 0.7071 - val_loss: 1.6273 - val_acc: 0.3929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00130: val_acc did not improve from 0.40179\n",
      "Epoch 131/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9661 - acc: 0.7101 - val_loss: 1.6338 - val_acc: 0.3929\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.40179\n",
      "Epoch 132/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9658 - acc: 0.7054 - val_loss: 1.6285 - val_acc: 0.3929\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.40179\n",
      "Epoch 133/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9568 - acc: 0.7199 - val_loss: 1.6296 - val_acc: 0.3929\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.40179\n",
      "Epoch 134/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9612 - acc: 0.7159 - val_loss: 1.6309 - val_acc: 0.3929\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.40179\n",
      "Epoch 135/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9775 - acc: 0.6984 - val_loss: 1.6302 - val_acc: 0.4018\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.40179\n",
      "Epoch 136/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9389 - acc: 0.7208 - val_loss: 1.6329 - val_acc: 0.4196\n",
      "\n",
      "Epoch 00136: val_acc improved from 0.40179 to 0.41964, saving model to weights-prolonged/improvement-136-0.42.hdf5\n",
      "Epoch 137/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9585 - acc: 0.7071 - val_loss: 1.6297 - val_acc: 0.4196\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.41964\n",
      "Epoch 138/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9604 - acc: 0.7145 - val_loss: 1.6290 - val_acc: 0.3929\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.41964\n",
      "Epoch 139/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9432 - acc: 0.7228 - val_loss: 1.6190 - val_acc: 0.3929\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.41964\n",
      "Epoch 140/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9540 - acc: 0.7115 - val_loss: 1.6258 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.41964\n",
      "Epoch 141/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9766 - acc: 0.7036 - val_loss: 1.6311 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.41964\n",
      "Epoch 142/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9490 - acc: 0.7244 - val_loss: 1.6228 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.41964\n",
      "Epoch 143/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9331 - acc: 0.7230 - val_loss: 1.6339 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.41964\n",
      "Epoch 144/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9448 - acc: 0.7264 - val_loss: 1.6230 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.41964\n",
      "Epoch 145/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9380 - acc: 0.7256 - val_loss: 1.6163 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.41964\n",
      "Epoch 146/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9451 - acc: 0.7213 - val_loss: 1.6200 - val_acc: 0.4196\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.41964\n",
      "Epoch 147/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9218 - acc: 0.7196 - val_loss: 1.6240 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.41964\n",
      "Epoch 148/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9140 - acc: 0.7274 - val_loss: 1.6184 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.41964\n",
      "Epoch 149/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9224 - acc: 0.7151 - val_loss: 1.6150 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.41964\n",
      "Epoch 150/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9025 - acc: 0.7345 - val_loss: 1.6160 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.41964\n",
      "Epoch 151/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9118 - acc: 0.7230 - val_loss: 1.6153 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.41964\n",
      "Epoch 152/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9226 - acc: 0.7157 - val_loss: 1.6230 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.41964\n",
      "Epoch 153/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9061 - acc: 0.7438 - val_loss: 1.6216 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.41964\n",
      "Epoch 154/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9113 - acc: 0.7246 - val_loss: 1.6148 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.41964\n",
      "Epoch 155/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9150 - acc: 0.7166 - val_loss: 1.6244 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.41964\n",
      "Epoch 156/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9149 - acc: 0.7284 - val_loss: 1.6070 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.41964\n",
      "Epoch 157/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8938 - acc: 0.7276 - val_loss: 1.6019 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00157: val_acc improved from 0.41964 to 0.42857, saving model to weights-prolonged/improvement-157-0.43.hdf5\n",
      "Epoch 158/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8909 - acc: 0.7347 - val_loss: 1.6137 - val_acc: 0.4196\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.42857\n",
      "Epoch 159/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8986 - acc: 0.7294 - val_loss: 1.6087 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.42857\n",
      "Epoch 160/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8843 - acc: 0.7318 - val_loss: 1.6105 - val_acc: 0.4196\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.42857\n",
      "Epoch 161/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8847 - acc: 0.7478 - val_loss: 1.6064 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.42857\n",
      "Epoch 162/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8917 - acc: 0.7409 - val_loss: 1.6030 - val_acc: 0.4196\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.42857\n",
      "Epoch 163/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8885 - acc: 0.7230 - val_loss: 1.6005 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.42857\n",
      "Epoch 164/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8950 - acc: 0.7268 - val_loss: 1.6120 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.42857\n",
      "Epoch 165/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8773 - acc: 0.7544 - val_loss: 1.6091 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.42857\n",
      "Epoch 166/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8743 - acc: 0.7528 - val_loss: 1.6089 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.42857\n",
      "Epoch 167/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8932 - acc: 0.7244 - val_loss: 1.6104 - val_acc: 0.4196\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.42857\n",
      "Epoch 168/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8669 - acc: 0.7460 - val_loss: 1.5985 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.42857\n",
      "Epoch 169/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8725 - acc: 0.7472 - val_loss: 1.5988 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.42857\n",
      "Epoch 170/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8737 - acc: 0.7300 - val_loss: 1.5971 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.42857\n",
      "Epoch 171/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8669 - acc: 0.7494 - val_loss: 1.5999 - val_acc: 0.4196\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.42857\n",
      "Epoch 172/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8836 - acc: 0.7413 - val_loss: 1.6068 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 0.42857\n",
      "Epoch 173/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8857 - acc: 0.7284 - val_loss: 1.6141 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.42857\n",
      "Epoch 174/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8683 - acc: 0.7417 - val_loss: 1.5942 - val_acc: 0.4196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00174: val_acc did not improve from 0.42857\n",
      "Epoch 175/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8691 - acc: 0.7343 - val_loss: 1.5991 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.42857\n",
      "Epoch 176/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8651 - acc: 0.7367 - val_loss: 1.6067 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 0.42857\n",
      "Epoch 177/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8534 - acc: 0.7345 - val_loss: 1.6072 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00177: val_acc improved from 0.42857 to 0.43750, saving model to weights-prolonged/improvement-177-0.44.hdf5\n",
      "Epoch 178/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8498 - acc: 0.7433 - val_loss: 1.5979 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.43750\n",
      "Epoch 179/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8645 - acc: 0.7312 - val_loss: 1.6011 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.43750\n",
      "Epoch 180/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8713 - acc: 0.7319 - val_loss: 1.6004 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.43750\n",
      "Epoch 181/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8479 - acc: 0.7383 - val_loss: 1.5976 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.43750\n",
      "Epoch 182/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8490 - acc: 0.7341 - val_loss: 1.5902 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.43750\n",
      "Epoch 183/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8250 - acc: 0.7567 - val_loss: 1.5987 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.43750\n",
      "Epoch 184/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8412 - acc: 0.7468 - val_loss: 1.5912 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.43750\n",
      "Epoch 185/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8317 - acc: 0.7472 - val_loss: 1.5961 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.43750\n",
      "Epoch 186/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8408 - acc: 0.7498 - val_loss: 1.5947 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 0.43750\n",
      "Epoch 187/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8323 - acc: 0.7583 - val_loss: 1.5883 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.43750\n",
      "Epoch 188/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8527 - acc: 0.7407 - val_loss: 1.6069 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.43750\n",
      "Epoch 189/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8405 - acc: 0.7461 - val_loss: 1.5975 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 0.43750\n",
      "Epoch 190/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8453 - acc: 0.7538 - val_loss: 1.5874 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.43750\n",
      "Epoch 191/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8350 - acc: 0.7353 - val_loss: 1.5983 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.43750\n",
      "Epoch 192/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8313 - acc: 0.7444 - val_loss: 1.5953 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.43750\n",
      "Epoch 193/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8285 - acc: 0.7421 - val_loss: 1.5882 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.43750\n",
      "Epoch 194/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8459 - acc: 0.7514 - val_loss: 1.5998 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 0.43750\n",
      "Epoch 195/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8010 - acc: 0.7653 - val_loss: 1.5946 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.43750\n",
      "Epoch 196/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7988 - acc: 0.7617 - val_loss: 1.5912 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.43750\n",
      "Epoch 197/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8146 - acc: 0.7440 - val_loss: 1.5871 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.43750\n",
      "Epoch 198/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8102 - acc: 0.7583 - val_loss: 1.5958 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.43750\n",
      "Epoch 199/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7879 - acc: 0.7728 - val_loss: 1.5833 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.43750\n",
      "Epoch 200/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8268 - acc: 0.7571 - val_loss: 1.5945 - val_acc: 0.4464\n",
      "\n",
      "Epoch 00200: val_acc improved from 0.43750 to 0.44643, saving model to weights-prolonged/improvement-200-0.45.hdf5\n",
      "Epoch 201/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8230 - acc: 0.7423 - val_loss: 1.5844 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00201: val_acc did not improve from 0.44643\n",
      "Epoch 202/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8016 - acc: 0.7528 - val_loss: 1.5841 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00202: val_acc did not improve from 0.44643\n",
      "Epoch 203/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8061 - acc: 0.7333 - val_loss: 1.5796 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00203: val_acc did not improve from 0.44643\n",
      "Epoch 204/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7999 - acc: 0.7740 - val_loss: 1.5958 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00204: val_acc did not improve from 0.44643\n",
      "Epoch 205/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8020 - acc: 0.7647 - val_loss: 1.5903 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00205: val_acc did not improve from 0.44643\n",
      "Epoch 206/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7974 - acc: 0.7714 - val_loss: 1.5888 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00206: val_acc did not improve from 0.44643\n",
      "Epoch 207/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8207 - acc: 0.7651 - val_loss: 1.5828 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00207: val_acc did not improve from 0.44643\n",
      "Epoch 208/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8012 - acc: 0.7613 - val_loss: 1.5878 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00208: val_acc did not improve from 0.44643\n",
      "Epoch 209/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8064 - acc: 0.7647 - val_loss: 1.5830 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00209: val_acc did not improve from 0.44643\n",
      "Epoch 210/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7750 - acc: 0.7682 - val_loss: 1.5930 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00210: val_acc did not improve from 0.44643\n",
      "Epoch 211/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8158 - acc: 0.7562 - val_loss: 1.6040 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00211: val_acc did not improve from 0.44643\n",
      "Epoch 212/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8045 - acc: 0.7692 - val_loss: 1.5944 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00212: val_acc did not improve from 0.44643\n",
      "Epoch 213/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7837 - acc: 0.7796 - val_loss: 1.5949 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00213: val_acc did not improve from 0.44643\n",
      "Epoch 214/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7746 - acc: 0.7748 - val_loss: 1.5930 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00214: val_acc did not improve from 0.44643\n",
      "Epoch 215/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7952 - acc: 0.7571 - val_loss: 1.5875 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00215: val_acc did not improve from 0.44643\n",
      "Epoch 216/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7934 - acc: 0.7746 - val_loss: 1.5928 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00216: val_acc did not improve from 0.44643\n",
      "Epoch 217/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7780 - acc: 0.7792 - val_loss: 1.5837 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00217: val_acc did not improve from 0.44643\n",
      "Epoch 218/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7743 - acc: 0.7770 - val_loss: 1.5814 - val_acc: 0.4375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00218: val_acc did not improve from 0.44643\n",
      "Epoch 219/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8065 - acc: 0.7597 - val_loss: 1.5820 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00219: val_acc did not improve from 0.44643\n",
      "Epoch 220/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7650 - acc: 0.7740 - val_loss: 1.5826 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00220: val_acc did not improve from 0.44643\n",
      "Epoch 221/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7784 - acc: 0.7591 - val_loss: 1.5908 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00221: val_acc did not improve from 0.44643\n",
      "Epoch 222/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7652 - acc: 0.7740 - val_loss: 1.5781 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00222: val_acc did not improve from 0.44643\n",
      "Epoch 223/300\n",
      " 9/63 [===>..........................] - ETA: 1:15 - loss: 0.7931 - acc: 0.7569"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-b7996912431a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m                     \u001b[0mnb_epoch\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                     \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpreprocessed_x_validation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_validation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                     callbacks = callbacks_list)\n\u001b[0m",
      "\u001b[1;32mc:\\users\\vibhu\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vibhu\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1413\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1414\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1415\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vibhu\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    211\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    212\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vibhu\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1214\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1215\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1216\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vibhu\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2664\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2666\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2667\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2668\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vibhu\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2635\u001b[0m                                 session)\n\u001b[1;32m-> 2636\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2637\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vibhu\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_generator,\n",
    "                    nb_epoch =300,\n",
    "                    validation_data = (preprocessed_x_validation, y_validation),\n",
    "                    callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open('model.json', 'w') as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.json') as file:\n",
    "    a=file.read()\n",
    "    model=model_from_json(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('weights-prolonged/improvement-03-0.54.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(Image.open('happy.jpg').resize((299,299)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 299, 299, 3)\n"
     ]
    }
   ],
   "source": [
    "a=np.expand_dims(x, axis=0)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_p=applications.xception.preprocess_input(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13262449, 0.06490922, 0.19013579, 0.15680768, 0.13341616,\n",
       "        0.2022113 , 0.11989541]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
