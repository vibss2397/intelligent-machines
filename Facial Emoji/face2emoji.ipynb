{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D, Reshape\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image\n",
    "import time\n",
    "import os\n",
    "import argparse\n",
    "import json\n",
    "\n",
    "k.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cropping because images contained timestamps\n",
    "\n",
    "# for folders in os.listdir('ck/img_divided'):\n",
    "#     for file in os.listdir('ck/img_divided/'+folders):\n",
    "#         img_arr=np.array(Image.open('ck/img_divided/'+folders+'/'+file))[12:-60]\n",
    "#         img=Image.fromarray(img_arr).save('Ck/img_divided2/'+folders+'/'+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 180\n",
    "nb_classes = 8\n",
    "batch_size = 16\n",
    "\n",
    "inputs={}\n",
    "inputs['vgg']=[224, 224]\n",
    "inputs['xception']=[299, 299]\n",
    "inputs['mobilenet']=[224, 224]\n",
    "\n",
    "classes_onehot = np.eye(8)\n",
    "learn_rate = 1e-4  # sgd learning rate\n",
    "momentum = .9  # sgd momentum to avoid local minimum\n",
    "transformation_ratio = .15  # how aggressive will be the data augmentation/transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xception=applications.xception.Xception(include_top=False, weights='imagenet')\n",
    "# vgg=applications.vgg16.VGG16(include_top=False, weights='imagenet')\n",
    "# mobilenet=applications.mobilenet.MobileNet(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(size, filename):\n",
    "    img_array = []\n",
    "    label_array = []\n",
    "    with open('ck/archive/image_mapping.json') as ma:\n",
    "        img_map = json.load(ma)\n",
    "    for file in os.listdir('ck/' + filename):\n",
    "        img=Image.open('ck/' + filename + '/' + file).convert('RGB')\n",
    "        img_array.append(np.array(img).reshape(size[0], size[1], 3))\n",
    "        label = img_map[file.split('.')[0]]['number']\n",
    "        label_onehot = classes_onehot[label]\n",
    "        label_array.append(label_onehot)\n",
    "    \n",
    "    return np.array(img_array), np.array(label_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name):\n",
    "    if model_name == 'xception':\n",
    "        xception=applications.xception.Xception(include_top=False, weights='imagenet')        \n",
    "        x = xception.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(128, activation='relu') (x)\n",
    "        predictions = Dense(nb_classes, activation='softmax')(x)    \n",
    "        model=Model(xception.input, predictions)\n",
    "        \n",
    "        for layer in xception.layers:\n",
    "            layer.trainable = False        \n",
    "    elif model_name == 'mobilenet':\n",
    "        mnet = applications.mobilenet.MobileNet(include_top=False, weights='imagenet')\n",
    "        x = mnet.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Reshape((none, 1, 1, 1024)) (x)\n",
    "        x = Dropout() (x)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=load_dataset(size = inputs['xception'], filename = 'img-xception')\n",
    "x_train, x_validation,y_train, y_validation = train_test_split(x, y, test_size = 0.10, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=get_model('xception')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, None, None, 3 864         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, None, None, 3 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, None, None, 3 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, None, None, 6 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, None, None, 6 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, None, None, 6 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, None, None, 1 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, None, None, 1 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, None, None, 1 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, None, None, 1 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, None, None, 1 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, None, 1 8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, None, None, 1 0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, None, 1 512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, None, None, 1 0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, None, None, 1 0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, None, None, 2 33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, None, None, 2 0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, None, None, 2 67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, None, 2 32768       add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, None, None, 2 0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, None, 2 1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, None, None, 2 0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, None, None, 2 0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, None, None, 7 188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, None, None, 7 0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, None, 7 186368      add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, None, None, 7 0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, None, None, 7 2912        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, None, None, 7 0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, None, None, 7 0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, None, None, 7 0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, None, None, 7 0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, None, None, 7 0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, None, None, 7 0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, None, None, 7 0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, None, None, 7 0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, None, None, 7 0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, None, None, 7 0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, None, None, 7 0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, None, None, 7 0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, None, None, 7 0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, None, None, 7 0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, None, None, 7 0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, None, None, 7 0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, None, None, 7 0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, None, None, 7 0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, None, None, 7 0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, None, None, 7 0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, None, None, 7 0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, None, None, 7 0           add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, None, None, 7 536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, None, None, 7 0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, None, None, 7 536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, None, None, 7 0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, None, None, 7 536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, None, None, 7 0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, None, None, 7 0           add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, None, None, 7 536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, None, None, 7 0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, None, None, 7 536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, None, None, 7 0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, None, None, 7 536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, None, None, 7 0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, None, None, 7 0           add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, None, None, 7 536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, None, None, 7 0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, None, None, 7 536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, None, None, 7 0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, None, None, 7 536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, None, None, 7 0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, None, None, 7 0           add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, None, None, 7 536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, None, None, 7 0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, None, None, 1 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, None, None, 1 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 1 745472      add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, None, None, 1 0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, None, None, 1 4096        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, None, None, 1 0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, None, None, 1 1582080     add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, None, None, 1 6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, None, None, 1 0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, None, None, 2 3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, None, None, 2 8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, None, None, 2 0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          262272      global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 8)            1032        dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 21,124,784\n",
      "Trainable params: 263,304\n",
      "Non-trainable params: 20,861,480\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_x_validation = applications.xception.preprocess_input(x_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=applications.xception.preprocess_input,\n",
    "                                       rotation_range=0.35,\n",
    "                                       shear_range=transformation_ratio,\n",
    "                                       zoom_range=transformation_ratio,\n",
    "                                       cval=transformation_ratio,\n",
    "                                       horizontal_flip=True)\n",
    "\n",
    "# validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "# x_validation = x_validation/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow(x_train, y_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# validation_generator = validation_datagen.flow(x_validation, y_validation, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir='logs-xception/{}'.format(time.time()), histogram_freq=1,\n",
    "                          write_graph=True, write_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.SGD(lr=learn_rate,decay=1e-6, momentum=momentum, nesterov=True), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"weights-overfit/improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vibhu\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  after removing the cwd from sys.path.\n",
      "c:\\users\\vibhu\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., callbacks=[<keras.ca..., epochs=300)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "63/63 [==============================] - 126s 2s/step - loss: 2.1459 - acc: 0.1113 - val_loss: 2.0908 - val_acc: 0.0893\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.08929, saving model to weights-overfit/improvement-01-0.09.hdf5\n",
      "Epoch 2/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 2.0581 - acc: 0.1182 - val_loss: 2.0450 - val_acc: 0.1250\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.08929 to 0.12500, saving model to weights-overfit/improvement-02-0.12.hdf5\n",
      "Epoch 3/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 2.0153 - acc: 0.1649 - val_loss: 2.0175 - val_acc: 0.1786\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.12500 to 0.17857, saving model to weights-overfit/improvement-03-0.18.hdf5\n",
      "Epoch 4/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.9811 - acc: 0.2161 - val_loss: 1.9986 - val_acc: 0.2500\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.17857 to 0.25000, saving model to weights-overfit/improvement-04-0.25.hdf5\n",
      "Epoch 5/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.9670 - acc: 0.2329 - val_loss: 1.9844 - val_acc: 0.2679\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.25000 to 0.26786, saving model to weights-overfit/improvement-05-0.27.hdf5\n",
      "Epoch 6/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.9475 - acc: 0.2516 - val_loss: 1.9754 - val_acc: 0.2946\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.26786 to 0.29464, saving model to weights-overfit/improvement-06-0.29.hdf5\n",
      "Epoch 7/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.9374 - acc: 0.2500 - val_loss: 1.9671 - val_acc: 0.3125\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.29464 to 0.31250, saving model to weights-overfit/improvement-07-0.31.hdf5\n",
      "Epoch 8/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.9217 - acc: 0.2579 - val_loss: 1.9609 - val_acc: 0.3214\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.31250 to 0.32143, saving model to weights-overfit/improvement-08-0.32.hdf5\n",
      "Epoch 9/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.9052 - acc: 0.2661 - val_loss: 1.9553 - val_acc: 0.3304\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.32143 to 0.33036, saving model to weights-overfit/improvement-09-0.33.hdf5\n",
      "Epoch 10/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.8980 - acc: 0.2944 - val_loss: 1.9499 - val_acc: 0.3214\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.33036\n",
      "Epoch 11/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.8865 - acc: 0.3058 - val_loss: 1.9458 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.33036 to 0.34821, saving model to weights-overfit/improvement-11-0.35.hdf5\n",
      "Epoch 12/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.8727 - acc: 0.3054 - val_loss: 1.9412 - val_acc: 0.3125\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.34821\n",
      "Epoch 13/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.8635 - acc: 0.3329 - val_loss: 1.9382 - val_acc: 0.3125\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.34821\n",
      "Epoch 14/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.8497 - acc: 0.3464 - val_loss: 1.9331 - val_acc: 0.3214\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.34821\n",
      "Epoch 15/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.8320 - acc: 0.3585 - val_loss: 1.9294 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.34821\n",
      "Epoch 16/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.8288 - acc: 0.3621 - val_loss: 1.9258 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.34821\n",
      "Epoch 17/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.8106 - acc: 0.3659 - val_loss: 1.9217 - val_acc: 0.3304\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.34821\n",
      "Epoch 18/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.7963 - acc: 0.3827 - val_loss: 1.9195 - val_acc: 0.3304\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.34821\n",
      "Epoch 19/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.7834 - acc: 0.3798 - val_loss: 1.9174 - val_acc: 0.3125\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.34821\n",
      "Epoch 20/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.7754 - acc: 0.4016 - val_loss: 1.9154 - val_acc: 0.2857\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.34821\n",
      "Epoch 21/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.7585 - acc: 0.4006 - val_loss: 1.9105 - val_acc: 0.2857\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.34821\n",
      "Epoch 22/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.7404 - acc: 0.4177 - val_loss: 1.9077 - val_acc: 0.2857\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.34821\n",
      "Epoch 23/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.7400 - acc: 0.4276 - val_loss: 1.9047 - val_acc: 0.2768\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.34821\n",
      "Epoch 24/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.7260 - acc: 0.4091 - val_loss: 1.9031 - val_acc: 0.2679\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.34821\n",
      "Epoch 25/300\n",
      "63/63 [==============================] - 101s 2s/step - loss: 1.7067 - acc: 0.4284 - val_loss: 1.8987 - val_acc: 0.2768\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.34821\n",
      "Epoch 26/300\n",
      "63/63 [==============================] - 100s 2s/step - loss: 1.6993 - acc: 0.4353 - val_loss: 1.8963 - val_acc: 0.2768\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.34821\n",
      "Epoch 27/300\n",
      "63/63 [==============================] - 100s 2s/step - loss: 1.6953 - acc: 0.4329 - val_loss: 1.8909 - val_acc: 0.2857\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.34821\n",
      "Epoch 28/300\n",
      "63/63 [==============================] - 100s 2s/step - loss: 1.6878 - acc: 0.4471 - val_loss: 1.8892 - val_acc: 0.2768\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.34821\n",
      "Epoch 29/300\n",
      "63/63 [==============================] - 100s 2s/step - loss: 1.6788 - acc: 0.4478 - val_loss: 1.8891 - val_acc: 0.2679\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.34821\n",
      "Epoch 30/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.6608 - acc: 0.4603 - val_loss: 1.8876 - val_acc: 0.2679\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.34821\n",
      "Epoch 31/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.6572 - acc: 0.4496 - val_loss: 1.8826 - val_acc: 0.2679\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.34821\n",
      "Epoch 32/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.6428 - acc: 0.4667 - val_loss: 1.8811 - val_acc: 0.2679\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.34821\n",
      "Epoch 33/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.6373 - acc: 0.4684 - val_loss: 1.8826 - val_acc: 0.2679\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.34821\n",
      "Epoch 34/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.6091 - acc: 0.4796 - val_loss: 1.8802 - val_acc: 0.2679\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.34821\n",
      "Epoch 35/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.6004 - acc: 0.4823 - val_loss: 1.8756 - val_acc: 0.2768\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.34821\n",
      "Epoch 36/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.5996 - acc: 0.4786 - val_loss: 1.8780 - val_acc: 0.2768\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.34821\n",
      "Epoch 37/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.5868 - acc: 0.4877 - val_loss: 1.8754 - val_acc: 0.2679\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.34821\n",
      "Epoch 38/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.5720 - acc: 0.4994 - val_loss: 1.8749 - val_acc: 0.2768\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.34821\n",
      "Epoch 39/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.5628 - acc: 0.4990 - val_loss: 1.8697 - val_acc: 0.2768\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.34821\n",
      "Epoch 40/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.5574 - acc: 0.5034 - val_loss: 1.8681 - val_acc: 0.2857\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.34821\n",
      "Epoch 41/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.5426 - acc: 0.5058 - val_loss: 1.8701 - val_acc: 0.2768\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.34821\n",
      "Epoch 42/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.5290 - acc: 0.5216 - val_loss: 1.8648 - val_acc: 0.2946\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.34821\n",
      "Epoch 43/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.5248 - acc: 0.5177 - val_loss: 1.8665 - val_acc: 0.2768\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.34821\n",
      "Epoch 44/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.5185 - acc: 0.5240 - val_loss: 1.8699 - val_acc: 0.2768\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.34821\n",
      "Epoch 45/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.5105 - acc: 0.5221 - val_loss: 1.8650 - val_acc: 0.2946\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.34821\n",
      "Epoch 46/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.4994 - acc: 0.5347 - val_loss: 1.8605 - val_acc: 0.2946\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.34821\n",
      "Epoch 47/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.4989 - acc: 0.5248 - val_loss: 1.8574 - val_acc: 0.2946\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.34821\n",
      "Epoch 48/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.4919 - acc: 0.5424 - val_loss: 1.8562 - val_acc: 0.2946\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.34821\n",
      "Epoch 49/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.4779 - acc: 0.5316 - val_loss: 1.8525 - val_acc: 0.2857\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.34821\n",
      "Epoch 50/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.4657 - acc: 0.5365 - val_loss: 1.8547 - val_acc: 0.2946\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.34821\n",
      "Epoch 51/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.4679 - acc: 0.5334 - val_loss: 1.8534 - val_acc: 0.2857\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.34821\n",
      "Epoch 52/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.4437 - acc: 0.5607 - val_loss: 1.8439 - val_acc: 0.3036\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.34821\n",
      "Epoch 53/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.4340 - acc: 0.5391 - val_loss: 1.8459 - val_acc: 0.2946\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.34821\n",
      "Epoch 54/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.4179 - acc: 0.5560 - val_loss: 1.8493 - val_acc: 0.2857\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.34821\n",
      "Epoch 55/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.4272 - acc: 0.5581 - val_loss: 1.8504 - val_acc: 0.2857\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.34821\n",
      "Epoch 56/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.4101 - acc: 0.5766 - val_loss: 1.8442 - val_acc: 0.2946\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.34821\n",
      "Epoch 57/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.4078 - acc: 0.5760 - val_loss: 1.8412 - val_acc: 0.3036\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.34821\n",
      "Epoch 58/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.3930 - acc: 0.5814 - val_loss: 1.8453 - val_acc: 0.2946\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.34821\n",
      "Epoch 59/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.4022 - acc: 0.5685 - val_loss: 1.8394 - val_acc: 0.3036\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.34821\n",
      "Epoch 60/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.3837 - acc: 0.5716 - val_loss: 1.8396 - val_acc: 0.3036\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.34821\n",
      "Epoch 61/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.3821 - acc: 0.5714 - val_loss: 1.8424 - val_acc: 0.3036\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.34821\n",
      "Epoch 62/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.3592 - acc: 0.5780 - val_loss: 1.8370 - val_acc: 0.3125\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.34821\n",
      "Epoch 63/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.3485 - acc: 0.5992 - val_loss: 1.8373 - val_acc: 0.3036\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.34821\n",
      "Epoch 64/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.3669 - acc: 0.5804 - val_loss: 1.8318 - val_acc: 0.3214\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.34821\n",
      "Epoch 65/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.3597 - acc: 0.5897 - val_loss: 1.8229 - val_acc: 0.3214\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.34821\n",
      "Epoch 66/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.3449 - acc: 0.5885 - val_loss: 1.8271 - val_acc: 0.3214\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.34821\n",
      "Epoch 67/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.3189 - acc: 0.6053 - val_loss: 1.8331 - val_acc: 0.3214\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.34821\n",
      "Epoch 68/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.3328 - acc: 0.5998 - val_loss: 1.8247 - val_acc: 0.3214\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.34821\n",
      "Epoch 69/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.3411 - acc: 0.5815 - val_loss: 1.8237 - val_acc: 0.3214\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.34821\n",
      "Epoch 70/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.3064 - acc: 0.6163 - val_loss: 1.8170 - val_acc: 0.3304\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.34821\n",
      "Epoch 71/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.3118 - acc: 0.5974 - val_loss: 1.8301 - val_acc: 0.3214\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.34821\n",
      "Epoch 72/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.2994 - acc: 0.5934 - val_loss: 1.8209 - val_acc: 0.3214\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.34821\n",
      "Epoch 73/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.2757 - acc: 0.6137 - val_loss: 1.8135 - val_acc: 0.3304\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.34821\n",
      "Epoch 74/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.2888 - acc: 0.6113 - val_loss: 1.8127 - val_acc: 0.3304\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.34821\n",
      "Epoch 75/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.2917 - acc: 0.6002 - val_loss: 1.8129 - val_acc: 0.3304\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.34821\n",
      "Epoch 76/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.2892 - acc: 0.6058 - val_loss: 1.8173 - val_acc: 0.3214\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.34821\n",
      "Epoch 77/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.2528 - acc: 0.6173 - val_loss: 1.8131 - val_acc: 0.3304\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.34821\n",
      "Epoch 78/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.2427 - acc: 0.6167 - val_loss: 1.8114 - val_acc: 0.3393\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.34821\n",
      "Epoch 79/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.2365 - acc: 0.6206 - val_loss: 1.8125 - val_acc: 0.3393\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.34821\n",
      "Epoch 80/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.2310 - acc: 0.6258 - val_loss: 1.8051 - val_acc: 0.3393\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.34821\n",
      "Epoch 81/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.2313 - acc: 0.6341 - val_loss: 1.8033 - val_acc: 0.3393\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.34821\n",
      "Epoch 82/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.2382 - acc: 0.6288 - val_loss: 1.7985 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.34821\n",
      "Epoch 83/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.2193 - acc: 0.6453 - val_loss: 1.8019 - val_acc: 0.3393\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.34821\n",
      "Epoch 84/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.2258 - acc: 0.6240 - val_loss: 1.8013 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.34821\n",
      "Epoch 85/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.2329 - acc: 0.6262 - val_loss: 1.8037 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.34821\n",
      "Epoch 86/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.2021 - acc: 0.6349 - val_loss: 1.7917 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00086: val_acc improved from 0.34821 to 0.35714, saving model to weights-overfit/improvement-86-0.36.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.2093 - acc: 0.6163 - val_loss: 1.7961 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.35714\n",
      "Epoch 88/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.2099 - acc: 0.6216 - val_loss: 1.7934 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.35714\n",
      "Epoch 89/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.2194 - acc: 0.6272 - val_loss: 1.8014 - val_acc: 0.3482\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.35714\n",
      "Epoch 90/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1833 - acc: 0.6417 - val_loss: 1.7958 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.35714\n",
      "Epoch 91/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1931 - acc: 0.6403 - val_loss: 1.7900 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.35714\n",
      "Epoch 92/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1845 - acc: 0.6365 - val_loss: 1.7870 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.35714\n",
      "Epoch 93/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1789 - acc: 0.6480 - val_loss: 1.7953 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.35714\n",
      "Epoch 94/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1597 - acc: 0.6454 - val_loss: 1.7876 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.35714\n",
      "Epoch 95/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1752 - acc: 0.6359 - val_loss: 1.7832 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.35714\n",
      "Epoch 96/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1764 - acc: 0.6492 - val_loss: 1.7797 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.35714\n",
      "Epoch 97/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1448 - acc: 0.6585 - val_loss: 1.7769 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.35714\n",
      "Epoch 98/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1517 - acc: 0.6526 - val_loss: 1.7851 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.35714\n",
      "Epoch 99/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1444 - acc: 0.6510 - val_loss: 1.7814 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.35714\n",
      "Epoch 100/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1700 - acc: 0.6486 - val_loss: 1.7744 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.35714\n",
      "Epoch 101/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1389 - acc: 0.6518 - val_loss: 1.7841 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.35714\n",
      "Epoch 102/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1394 - acc: 0.6607 - val_loss: 1.7764 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.35714\n",
      "Epoch 103/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1361 - acc: 0.6708 - val_loss: 1.7702 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.35714\n",
      "Epoch 104/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1318 - acc: 0.6480 - val_loss: 1.7713 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.35714\n",
      "Epoch 105/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1451 - acc: 0.6474 - val_loss: 1.7688 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.35714\n",
      "Epoch 106/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1281 - acc: 0.6639 - val_loss: 1.7717 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.35714\n",
      "Epoch 107/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1081 - acc: 0.6691 - val_loss: 1.7664 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.35714\n",
      "Epoch 108/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0999 - acc: 0.6587 - val_loss: 1.7634 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.35714\n",
      "Epoch 109/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1043 - acc: 0.6762 - val_loss: 1.7668 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.35714\n",
      "Epoch 110/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1023 - acc: 0.6698 - val_loss: 1.7713 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.35714\n",
      "Epoch 111/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1122 - acc: 0.6794 - val_loss: 1.7647 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.35714\n",
      "Epoch 112/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1078 - acc: 0.6528 - val_loss: 1.7715 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.35714\n",
      "Epoch 113/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0921 - acc: 0.6653 - val_loss: 1.7589 - val_acc: 0.3661\n",
      "\n",
      "Epoch 00113: val_acc improved from 0.35714 to 0.36607, saving model to weights-overfit/improvement-113-0.37.hdf5\n",
      "Epoch 114/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.1020 - acc: 0.6583 - val_loss: 1.7678 - val_acc: 0.3661\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.36607\n",
      "Epoch 115/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0825 - acc: 0.6579 - val_loss: 1.7628 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.36607\n",
      "Epoch 116/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0747 - acc: 0.6847 - val_loss: 1.7584 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.36607\n",
      "Epoch 117/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0851 - acc: 0.6639 - val_loss: 1.7620 - val_acc: 0.3661\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.36607\n",
      "Epoch 118/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0652 - acc: 0.6829 - val_loss: 1.7543 - val_acc: 0.3661\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.36607\n",
      "Epoch 119/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0716 - acc: 0.6704 - val_loss: 1.7527 - val_acc: 0.3661\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.36607\n",
      "Epoch 120/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0521 - acc: 0.6772 - val_loss: 1.7514 - val_acc: 0.3661\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.36607\n",
      "Epoch 121/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0546 - acc: 0.6907 - val_loss: 1.7632 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.36607\n",
      "Epoch 122/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0568 - acc: 0.6697 - val_loss: 1.7601 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00122: val_acc improved from 0.36607 to 0.37500, saving model to weights-overfit/improvement-122-0.38.hdf5\n",
      "Epoch 123/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0418 - acc: 0.6802 - val_loss: 1.7565 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.37500\n",
      "Epoch 124/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0524 - acc: 0.6643 - val_loss: 1.7557 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.37500\n",
      "Epoch 125/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0525 - acc: 0.7020 - val_loss: 1.7489 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.37500\n",
      "Epoch 126/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0418 - acc: 0.6760 - val_loss: 1.7441 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.37500\n",
      "Epoch 127/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0336 - acc: 0.6784 - val_loss: 1.7480 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.37500\n",
      "Epoch 128/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0321 - acc: 0.6748 - val_loss: 1.7529 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.37500\n",
      "Epoch 129/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0582 - acc: 0.6730 - val_loss: 1.7414 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.37500\n",
      "Epoch 130/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0231 - acc: 0.6901 - val_loss: 1.7402 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.37500\n",
      "Epoch 131/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 99s 2s/step - loss: 1.0162 - acc: 0.6956 - val_loss: 1.7390 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.37500\n",
      "Epoch 132/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0239 - acc: 0.6938 - val_loss: 1.7489 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.37500\n",
      "Epoch 133/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0540 - acc: 0.6738 - val_loss: 1.7426 - val_acc: 0.3839\n",
      "\n",
      "Epoch 00133: val_acc improved from 0.37500 to 0.38393, saving model to weights-overfit/improvement-133-0.38.hdf5\n",
      "Epoch 134/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0081 - acc: 0.6901 - val_loss: 1.7467 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.38393\n",
      "Epoch 135/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0218 - acc: 0.6827 - val_loss: 1.7492 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.38393\n",
      "Epoch 136/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0024 - acc: 0.6988 - val_loss: 1.7412 - val_acc: 0.3839\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.38393\n",
      "Epoch 137/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0076 - acc: 0.6895 - val_loss: 1.7493 - val_acc: 0.3750\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.38393\n",
      "Epoch 138/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0110 - acc: 0.6927 - val_loss: 1.7423 - val_acc: 0.3839\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.38393\n",
      "Epoch 139/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9993 - acc: 0.7051 - val_loss: 1.7385 - val_acc: 0.3839\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.38393\n",
      "Epoch 140/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9966 - acc: 0.7016 - val_loss: 1.7310 - val_acc: 0.3839\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.38393\n",
      "Epoch 141/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0222 - acc: 0.6808 - val_loss: 1.7341 - val_acc: 0.3839\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.38393\n",
      "Epoch 142/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9967 - acc: 0.6817 - val_loss: 1.7459 - val_acc: 0.3839\n",
      "\n",
      "Epoch 00142: val_acc improved from 0.38393 to 0.38393, saving model to weights-overfit/improvement-142-0.38.hdf5\n",
      "Epoch 143/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0016 - acc: 0.7026 - val_loss: 1.7332 - val_acc: 0.3839\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.38393\n",
      "Epoch 144/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9757 - acc: 0.7012 - val_loss: 1.7319 - val_acc: 0.3839\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.38393\n",
      "Epoch 145/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9925 - acc: 0.7030 - val_loss: 1.7301 - val_acc: 0.3839\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.38393\n",
      "Epoch 146/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 1.0036 - acc: 0.6903 - val_loss: 1.7288 - val_acc: 0.3839\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.38393\n",
      "Epoch 147/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9971 - acc: 0.6990 - val_loss: 1.7298 - val_acc: 0.3839\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.38393\n",
      "Epoch 148/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9579 - acc: 0.7107 - val_loss: 1.7273 - val_acc: 0.3929\n",
      "\n",
      "Epoch 00148: val_acc improved from 0.38393 to 0.39286, saving model to weights-overfit/improvement-148-0.39.hdf5\n",
      "Epoch 149/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9634 - acc: 0.7095 - val_loss: 1.7204 - val_acc: 0.3929\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.39286\n",
      "Epoch 150/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9770 - acc: 0.7006 - val_loss: 1.7327 - val_acc: 0.3839\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.39286\n",
      "Epoch 151/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9723 - acc: 0.6931 - val_loss: 1.7186 - val_acc: 0.3929\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.39286\n",
      "Epoch 152/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9647 - acc: 0.7075 - val_loss: 1.7143 - val_acc: 0.4018\n",
      "\n",
      "Epoch 00152: val_acc improved from 0.39286 to 0.40179, saving model to weights-overfit/improvement-152-0.40.hdf5\n",
      "Epoch 153/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9448 - acc: 0.7097 - val_loss: 1.7175 - val_acc: 0.4018\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.40179\n",
      "Epoch 154/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9600 - acc: 0.7095 - val_loss: 1.7315 - val_acc: 0.3929\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.40179\n",
      "Epoch 155/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9761 - acc: 0.7002 - val_loss: 1.7324 - val_acc: 0.3929\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.40179\n",
      "Epoch 156/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9626 - acc: 0.7107 - val_loss: 1.7206 - val_acc: 0.3929\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.40179\n",
      "Epoch 157/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9484 - acc: 0.7064 - val_loss: 1.7087 - val_acc: 0.4018\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.40179\n",
      "Epoch 158/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9502 - acc: 0.6911 - val_loss: 1.7147 - val_acc: 0.4018\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.40179\n",
      "Epoch 159/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9409 - acc: 0.7199 - val_loss: 1.7123 - val_acc: 0.3929\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.40179\n",
      "Epoch 160/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9492 - acc: 0.7145 - val_loss: 1.7146 - val_acc: 0.4018\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.40179\n",
      "Epoch 161/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9419 - acc: 0.7020 - val_loss: 1.7074 - val_acc: 0.4018\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.40179\n",
      "Epoch 162/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9495 - acc: 0.6917 - val_loss: 1.7084 - val_acc: 0.4018\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.40179\n",
      "Epoch 163/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9398 - acc: 0.7065 - val_loss: 1.7037 - val_acc: 0.4018\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.40179\n",
      "Epoch 164/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9366 - acc: 0.7091 - val_loss: 1.7031 - val_acc: 0.4018\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.40179\n",
      "Epoch 165/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9369 - acc: 0.7141 - val_loss: 1.7052 - val_acc: 0.4018\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.40179\n",
      "Epoch 166/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9344 - acc: 0.7079 - val_loss: 1.7068 - val_acc: 0.4018\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.40179\n",
      "Epoch 167/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9385 - acc: 0.7127 - val_loss: 1.7190 - val_acc: 0.4018\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.40179\n",
      "Epoch 168/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9352 - acc: 0.7186 - val_loss: 1.7105 - val_acc: 0.4018\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.40179\n",
      "Epoch 169/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9069 - acc: 0.7131 - val_loss: 1.7069 - val_acc: 0.4018\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.40179\n",
      "Epoch 170/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9302 - acc: 0.7185 - val_loss: 1.7168 - val_acc: 0.4018\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.40179\n",
      "Epoch 171/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9310 - acc: 0.7185 - val_loss: 1.7133 - val_acc: 0.4018\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.40179\n",
      "Epoch 172/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9087 - acc: 0.7294 - val_loss: 1.7134 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00172: val_acc improved from 0.40179 to 0.41071, saving model to weights-overfit/improvement-172-0.41.hdf5\n",
      "Epoch 173/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9013 - acc: 0.7056 - val_loss: 1.6925 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.41071\n",
      "Epoch 174/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 99s 2s/step - loss: 0.9454 - acc: 0.7061 - val_loss: 1.7049 - val_acc: 0.4018\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.41071\n",
      "Epoch 175/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8948 - acc: 0.7260 - val_loss: 1.6967 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.41071\n",
      "Epoch 176/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9020 - acc: 0.7220 - val_loss: 1.6986 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 0.41071\n",
      "Epoch 177/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9207 - acc: 0.7111 - val_loss: 1.7092 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.41071\n",
      "Epoch 178/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8614 - acc: 0.7291 - val_loss: 1.7026 - val_acc: 0.4196\n",
      "\n",
      "Epoch 00178: val_acc improved from 0.41071 to 0.41964, saving model to weights-overfit/improvement-178-0.42.hdf5\n",
      "Epoch 179/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8982 - acc: 0.7242 - val_loss: 1.7037 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.41964\n",
      "Epoch 180/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8876 - acc: 0.7216 - val_loss: 1.7013 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.41964\n",
      "Epoch 181/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8860 - acc: 0.7246 - val_loss: 1.7078 - val_acc: 0.4196\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.41964\n",
      "Epoch 182/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8856 - acc: 0.7193 - val_loss: 1.6989 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.41964\n",
      "Epoch 183/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8928 - acc: 0.7216 - val_loss: 1.6949 - val_acc: 0.4196\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.41964\n",
      "Epoch 184/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8649 - acc: 0.7419 - val_loss: 1.7007 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.41964\n",
      "Epoch 185/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9091 - acc: 0.7119 - val_loss: 1.6941 - val_acc: 0.4196\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.41964\n",
      "Epoch 186/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8879 - acc: 0.7410 - val_loss: 1.6924 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 0.41964\n",
      "Epoch 187/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8851 - acc: 0.7323 - val_loss: 1.6859 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.41964\n",
      "Epoch 188/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.9013 - acc: 0.7213 - val_loss: 1.6993 - val_acc: 0.4196\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.41964\n",
      "Epoch 189/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8549 - acc: 0.7419 - val_loss: 1.6930 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 0.41964\n",
      "Epoch 190/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8728 - acc: 0.7294 - val_loss: 1.6868 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.41964\n",
      "Epoch 191/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8980 - acc: 0.7115 - val_loss: 1.6982 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.41964\n",
      "Epoch 192/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8944 - acc: 0.7169 - val_loss: 1.6918 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.41964\n",
      "Epoch 193/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8722 - acc: 0.7250 - val_loss: 1.6952 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.41964\n",
      "Epoch 194/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8844 - acc: 0.7333 - val_loss: 1.6906 - val_acc: 0.4018\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 0.41964\n",
      "Epoch 195/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8865 - acc: 0.7325 - val_loss: 1.6937 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.41964\n",
      "Epoch 196/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8522 - acc: 0.7393 - val_loss: 1.6866 - val_acc: 0.4018\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.41964\n",
      "Epoch 197/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8640 - acc: 0.7331 - val_loss: 1.6866 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.41964\n",
      "Epoch 198/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8750 - acc: 0.7333 - val_loss: 1.6834 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.41964\n",
      "Epoch 199/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8335 - acc: 0.7478 - val_loss: 1.6813 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.41964\n",
      "Epoch 200/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8647 - acc: 0.7258 - val_loss: 1.6819 - val_acc: 0.4018\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.41964\n",
      "Epoch 201/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8436 - acc: 0.7403 - val_loss: 1.6819 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00201: val_acc did not improve from 0.41964\n",
      "Epoch 202/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8471 - acc: 0.7304 - val_loss: 1.6825 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00202: val_acc did not improve from 0.41964\n",
      "Epoch 203/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8499 - acc: 0.7452 - val_loss: 1.6752 - val_acc: 0.4196\n",
      "\n",
      "Epoch 00203: val_acc did not improve from 0.41964\n",
      "Epoch 204/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8611 - acc: 0.7220 - val_loss: 1.6903 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00204: val_acc did not improve from 0.41964\n",
      "Epoch 205/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8348 - acc: 0.7462 - val_loss: 1.6810 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00205: val_acc improved from 0.41964 to 0.42857, saving model to weights-overfit/improvement-205-0.43.hdf5\n",
      "Epoch 206/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8547 - acc: 0.7452 - val_loss: 1.6723 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00206: val_acc did not improve from 0.42857\n",
      "Epoch 207/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8434 - acc: 0.7409 - val_loss: 1.6885 - val_acc: 0.3929\n",
      "\n",
      "Epoch 00207: val_acc did not improve from 0.42857\n",
      "Epoch 208/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8442 - acc: 0.7452 - val_loss: 1.6601 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00208: val_acc did not improve from 0.42857\n",
      "Epoch 209/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8431 - acc: 0.7466 - val_loss: 1.6898 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00209: val_acc did not improve from 0.42857\n",
      "Epoch 210/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8350 - acc: 0.7480 - val_loss: 1.6706 - val_acc: 0.4196\n",
      "\n",
      "Epoch 00210: val_acc did not improve from 0.42857\n",
      "Epoch 211/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8315 - acc: 0.7377 - val_loss: 1.6716 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00211: val_acc did not improve from 0.42857\n",
      "Epoch 212/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8163 - acc: 0.7438 - val_loss: 1.6726 - val_acc: 0.4196\n",
      "\n",
      "Epoch 00212: val_acc did not improve from 0.42857\n",
      "Epoch 213/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8307 - acc: 0.7512 - val_loss: 1.6649 - val_acc: 0.4196\n",
      "\n",
      "Epoch 00213: val_acc did not improve from 0.42857\n",
      "Epoch 214/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8355 - acc: 0.7319 - val_loss: 1.6748 - val_acc: 0.4196\n",
      "\n",
      "Epoch 00214: val_acc did not improve from 0.42857\n",
      "Epoch 215/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8365 - acc: 0.7369 - val_loss: 1.6749 - val_acc: 0.4196\n",
      "\n",
      "Epoch 00215: val_acc did not improve from 0.42857\n",
      "Epoch 216/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8212 - acc: 0.7486 - val_loss: 1.6703 - val_acc: 0.4196\n",
      "\n",
      "Epoch 00216: val_acc did not improve from 0.42857\n",
      "Epoch 217/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8321 - acc: 0.7337 - val_loss: 1.6832 - val_acc: 0.4018\n",
      "\n",
      "Epoch 00217: val_acc did not improve from 0.42857\n",
      "Epoch 218/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 99s 2s/step - loss: 0.8157 - acc: 0.7363 - val_loss: 1.6800 - val_acc: 0.4018\n",
      "\n",
      "Epoch 00218: val_acc did not improve from 0.42857\n",
      "Epoch 219/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8254 - acc: 0.7452 - val_loss: 1.6810 - val_acc: 0.3929\n",
      "\n",
      "Epoch 00219: val_acc did not improve from 0.42857\n",
      "Epoch 220/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8382 - acc: 0.7312 - val_loss: 1.6741 - val_acc: 0.4196\n",
      "\n",
      "Epoch 00220: val_acc did not improve from 0.42857\n",
      "Epoch 221/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8217 - acc: 0.7421 - val_loss: 1.6828 - val_acc: 0.4018\n",
      "\n",
      "Epoch 00221: val_acc did not improve from 0.42857\n",
      "Epoch 222/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8210 - acc: 0.7450 - val_loss: 1.6822 - val_acc: 0.4018\n",
      "\n",
      "Epoch 00222: val_acc did not improve from 0.42857\n",
      "Epoch 223/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7851 - acc: 0.7651 - val_loss: 1.6734 - val_acc: 0.4196\n",
      "\n",
      "Epoch 00223: val_acc did not improve from 0.42857\n",
      "Epoch 224/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7963 - acc: 0.7732 - val_loss: 1.6790 - val_acc: 0.4196\n",
      "\n",
      "Epoch 00224: val_acc did not improve from 0.42857\n",
      "Epoch 225/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8182 - acc: 0.7502 - val_loss: 1.6813 - val_acc: 0.4018\n",
      "\n",
      "Epoch 00225: val_acc did not improve from 0.42857\n",
      "Epoch 226/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8072 - acc: 0.7552 - val_loss: 1.6710 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00226: val_acc improved from 0.42857 to 0.43750, saving model to weights-overfit/improvement-226-0.44.hdf5\n",
      "Epoch 227/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8096 - acc: 0.7518 - val_loss: 1.6816 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00227: val_acc did not improve from 0.43750\n",
      "Epoch 228/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7984 - acc: 0.7544 - val_loss: 1.6680 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00228: val_acc did not improve from 0.43750\n",
      "Epoch 229/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7925 - acc: 0.7571 - val_loss: 1.6690 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00229: val_acc did not improve from 0.43750\n",
      "Epoch 230/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7835 - acc: 0.7613 - val_loss: 1.6706 - val_acc: 0.4196\n",
      "\n",
      "Epoch 00230: val_acc did not improve from 0.43750\n",
      "Epoch 231/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8170 - acc: 0.7415 - val_loss: 1.6767 - val_acc: 0.4018\n",
      "\n",
      "Epoch 00231: val_acc did not improve from 0.43750\n",
      "Epoch 232/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8132 - acc: 0.7314 - val_loss: 1.6721 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00232: val_acc did not improve from 0.43750\n",
      "Epoch 233/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8163 - acc: 0.7427 - val_loss: 1.6700 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00233: val_acc did not improve from 0.43750\n",
      "Epoch 234/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7979 - acc: 0.7720 - val_loss: 1.6829 - val_acc: 0.4196\n",
      "\n",
      "Epoch 00234: val_acc did not improve from 0.43750\n",
      "Epoch 235/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8150 - acc: 0.7322 - val_loss: 1.6698 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00235: val_acc did not improve from 0.43750\n",
      "Epoch 236/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7963 - acc: 0.7685 - val_loss: 1.6569 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00236: val_acc did not improve from 0.43750\n",
      "Epoch 237/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7800 - acc: 0.7542 - val_loss: 1.6650 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00237: val_acc did not improve from 0.43750\n",
      "Epoch 238/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7856 - acc: 0.7657 - val_loss: 1.6675 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00238: val_acc did not improve from 0.43750\n",
      "Epoch 239/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7886 - acc: 0.7635 - val_loss: 1.6660 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00239: val_acc did not improve from 0.43750\n",
      "Epoch 240/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7830 - acc: 0.7571 - val_loss: 1.6679 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00240: val_acc did not improve from 0.43750\n",
      "Epoch 241/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7929 - acc: 0.7557 - val_loss: 1.6831 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00241: val_acc did not improve from 0.43750\n",
      "Epoch 242/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.8014 - acc: 0.7522 - val_loss: 1.6703 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00242: val_acc did not improve from 0.43750\n",
      "Epoch 243/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7821 - acc: 0.7433 - val_loss: 1.6601 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00243: val_acc did not improve from 0.43750\n",
      "Epoch 244/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7882 - acc: 0.7617 - val_loss: 1.6663 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00244: val_acc did not improve from 0.43750\n",
      "Epoch 245/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7555 - acc: 0.7756 - val_loss: 1.6641 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00245: val_acc improved from 0.43750 to 0.43750, saving model to weights-overfit/improvement-245-0.44.hdf5\n",
      "Epoch 246/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7947 - acc: 0.7542 - val_loss: 1.6556 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00246: val_acc did not improve from 0.43750\n",
      "Epoch 247/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7827 - acc: 0.7786 - val_loss: 1.6538 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00247: val_acc did not improve from 0.43750\n",
      "Epoch 248/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7644 - acc: 0.7726 - val_loss: 1.6595 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00248: val_acc did not improve from 0.43750\n",
      "Epoch 249/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7710 - acc: 0.7617 - val_loss: 1.6739 - val_acc: 0.4196\n",
      "\n",
      "Epoch 00249: val_acc did not improve from 0.43750\n",
      "Epoch 250/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7584 - acc: 0.7696 - val_loss: 1.6711 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00250: val_acc did not improve from 0.43750\n",
      "Epoch 251/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7568 - acc: 0.7661 - val_loss: 1.6630 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00251: val_acc did not improve from 0.43750\n",
      "Epoch 252/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7453 - acc: 0.7681 - val_loss: 1.6725 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00252: val_acc did not improve from 0.43750\n",
      "Epoch 253/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7654 - acc: 0.7710 - val_loss: 1.6674 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00253: val_acc did not improve from 0.43750\n",
      "Epoch 254/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7609 - acc: 0.7623 - val_loss: 1.6786 - val_acc: 0.4196\n",
      "\n",
      "Epoch 00254: val_acc did not improve from 0.43750\n",
      "Epoch 255/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7577 - acc: 0.7677 - val_loss: 1.6689 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00255: val_acc did not improve from 0.43750\n",
      "Epoch 256/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7678 - acc: 0.7546 - val_loss: 1.6647 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00256: val_acc did not improve from 0.43750\n",
      "Epoch 257/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7825 - acc: 0.7583 - val_loss: 1.6649 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00257: val_acc did not improve from 0.43750\n",
      "Epoch 258/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7308 - acc: 0.7756 - val_loss: 1.6654 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00258: val_acc did not improve from 0.43750\n",
      "Epoch 259/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7448 - acc: 0.7641 - val_loss: 1.6670 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00259: val_acc did not improve from 0.43750\n",
      "Epoch 260/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7507 - acc: 0.7706 - val_loss: 1.6737 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00260: val_acc did not improve from 0.43750\n",
      "Epoch 261/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7561 - acc: 0.7637 - val_loss: 1.6744 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00261: val_acc did not improve from 0.43750\n",
      "Epoch 262/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 99s 2s/step - loss: 0.7627 - acc: 0.7643 - val_loss: 1.6687 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00262: val_acc did not improve from 0.43750\n",
      "Epoch 263/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7386 - acc: 0.7834 - val_loss: 1.6829 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00263: val_acc did not improve from 0.43750\n",
      "Epoch 264/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7591 - acc: 0.7573 - val_loss: 1.6725 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00264: val_acc did not improve from 0.43750\n",
      "Epoch 265/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7424 - acc: 0.7571 - val_loss: 1.6797 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00265: val_acc did not improve from 0.43750\n",
      "Epoch 266/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7486 - acc: 0.7583 - val_loss: 1.6718 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00266: val_acc did not improve from 0.43750\n",
      "Epoch 267/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7428 - acc: 0.7663 - val_loss: 1.6666 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00267: val_acc did not improve from 0.43750\n",
      "Epoch 268/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7436 - acc: 0.7716 - val_loss: 1.6730 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00268: val_acc did not improve from 0.43750\n",
      "Epoch 269/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7541 - acc: 0.7593 - val_loss: 1.6944 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00269: val_acc did not improve from 0.43750\n",
      "Epoch 270/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7613 - acc: 0.7641 - val_loss: 1.6654 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00270: val_acc did not improve from 0.43750\n",
      "Epoch 271/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7144 - acc: 0.7776 - val_loss: 1.6637 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00271: val_acc did not improve from 0.43750\n",
      "Epoch 272/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7209 - acc: 0.7723 - val_loss: 1.6641 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00272: val_acc did not improve from 0.43750\n",
      "Epoch 273/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7600 - acc: 0.7657 - val_loss: 1.6576 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00273: val_acc did not improve from 0.43750\n",
      "Epoch 274/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7186 - acc: 0.7740 - val_loss: 1.6712 - val_acc: 0.4196\n",
      "\n",
      "Epoch 00274: val_acc did not improve from 0.43750\n",
      "Epoch 275/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7292 - acc: 0.7851 - val_loss: 1.6699 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00275: val_acc did not improve from 0.43750\n",
      "Epoch 276/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7258 - acc: 0.7792 - val_loss: 1.6663 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00276: val_acc did not improve from 0.43750\n",
      "Epoch 277/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7432 - acc: 0.7811 - val_loss: 1.6656 - val_acc: 0.4196\n",
      "\n",
      "Epoch 00277: val_acc did not improve from 0.43750\n",
      "Epoch 278/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7362 - acc: 0.7659 - val_loss: 1.6727 - val_acc: 0.4196\n",
      "\n",
      "Epoch 00278: val_acc did not improve from 0.43750\n",
      "Epoch 279/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7460 - acc: 0.7744 - val_loss: 1.6678 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00279: val_acc did not improve from 0.43750\n",
      "Epoch 280/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7194 - acc: 0.7772 - val_loss: 1.6583 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00280: val_acc did not improve from 0.43750\n",
      "Epoch 281/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7181 - acc: 0.7806 - val_loss: 1.6500 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00281: val_acc did not improve from 0.43750\n",
      "Epoch 282/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7160 - acc: 0.7851 - val_loss: 1.6581 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00282: val_acc did not improve from 0.43750\n",
      "Epoch 283/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7216 - acc: 0.7800 - val_loss: 1.6660 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00283: val_acc did not improve from 0.43750\n",
      "Epoch 284/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7259 - acc: 0.7712 - val_loss: 1.6629 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00284: val_acc did not improve from 0.43750\n",
      "Epoch 285/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7266 - acc: 0.7726 - val_loss: 1.6730 - val_acc: 0.4196\n",
      "\n",
      "Epoch 00285: val_acc did not improve from 0.43750\n",
      "Epoch 286/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7073 - acc: 0.7845 - val_loss: 1.6687 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00286: val_acc did not improve from 0.43750\n",
      "Epoch 287/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7014 - acc: 0.7869 - val_loss: 1.6643 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00287: val_acc did not improve from 0.43750\n",
      "Epoch 288/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7022 - acc: 0.7762 - val_loss: 1.6717 - val_acc: 0.4196\n",
      "\n",
      "Epoch 00288: val_acc did not improve from 0.43750\n",
      "Epoch 289/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7145 - acc: 0.7829 - val_loss: 1.6543 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00289: val_acc did not improve from 0.43750\n",
      "Epoch 290/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7087 - acc: 0.7911 - val_loss: 1.6559 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00290: val_acc did not improve from 0.43750\n",
      "Epoch 291/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7105 - acc: 0.7939 - val_loss: 1.6650 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00291: val_acc did not improve from 0.43750\n",
      "Epoch 292/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.7114 - acc: 0.7861 - val_loss: 1.6690 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00292: val_acc did not improve from 0.43750\n",
      "Epoch 293/300\n",
      "63/63 [==============================] - 100s 2s/step - loss: 0.7039 - acc: 0.8044 - val_loss: 1.6510 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00293: val_acc did not improve from 0.43750\n",
      "Epoch 294/300\n",
      "63/63 [==============================] - 100s 2s/step - loss: 0.6987 - acc: 0.7865 - val_loss: 1.6432 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00294: val_acc did not improve from 0.43750\n",
      "Epoch 295/300\n",
      "63/63 [==============================] - 100s 2s/step - loss: 0.6921 - acc: 0.7957 - val_loss: 1.6506 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00295: val_acc did not improve from 0.43750\n",
      "Epoch 296/300\n",
      "63/63 [==============================] - 100s 2s/step - loss: 0.7060 - acc: 0.7861 - val_loss: 1.6572 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00296: val_acc did not improve from 0.43750\n",
      "Epoch 297/300\n",
      "63/63 [==============================] - 100s 2s/step - loss: 0.7164 - acc: 0.7810 - val_loss: 1.6576 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00297: val_acc did not improve from 0.43750\n",
      "Epoch 298/300\n",
      "63/63 [==============================] - 100s 2s/step - loss: 0.7277 - acc: 0.7712 - val_loss: 1.6538 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00298: val_acc did not improve from 0.43750\n",
      "Epoch 299/300\n",
      "63/63 [==============================] - 100s 2s/step - loss: 0.7051 - acc: 0.7944 - val_loss: 1.6615 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00299: val_acc did not improve from 0.43750\n",
      "Epoch 300/300\n",
      "63/63 [==============================] - 100s 2s/step - loss: 0.6780 - acc: 0.7935 - val_loss: 1.6651 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00300: val_acc did not improve from 0.43750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x245b99bad30>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator,\n",
    "                    nb_epoch =300,\n",
    "                    validation_data = (preprocessed_x_validation, y_validation),\n",
    "                    callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vibhu\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  after removing the cwd from sys.path.\n",
      "c:\\users\\vibhu\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., callbacks=[<keras.ca..., epochs=300)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "63/63 [==============================] - 100s 2s/step - loss: 0.7222 - acc: 0.7738 - val_loss: 1.6618 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.43750\n",
      "Epoch 2/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6924 - acc: 0.7851 - val_loss: 1.6590 - val_acc: 0.4196\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.43750\n",
      "Epoch 3/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6871 - acc: 0.7984 - val_loss: 1.6588 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.43750\n",
      "Epoch 4/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6997 - acc: 0.7930 - val_loss: 1.6568 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.43750\n",
      "Epoch 5/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6936 - acc: 0.7851 - val_loss: 1.6741 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.43750\n",
      "Epoch 6/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6812 - acc: 0.7905 - val_loss: 1.6670 - val_acc: 0.4196\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.43750\n",
      "Epoch 7/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6935 - acc: 0.7756 - val_loss: 1.6482 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.43750\n",
      "Epoch 8/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6695 - acc: 0.7990 - val_loss: 1.6448 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.43750\n",
      "Epoch 9/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6927 - acc: 0.7925 - val_loss: 1.6566 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.43750\n",
      "Epoch 10/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6826 - acc: 0.7905 - val_loss: 1.6636 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.43750\n",
      "Epoch 11/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6899 - acc: 0.7889 - val_loss: 1.6605 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.43750\n",
      "Epoch 12/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6912 - acc: 0.7869 - val_loss: 1.6753 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.43750\n",
      "Epoch 13/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6822 - acc: 0.7875 - val_loss: 1.6685 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.43750\n",
      "Epoch 14/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6703 - acc: 0.7950 - val_loss: 1.6596 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.43750\n",
      "Epoch 15/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6956 - acc: 0.7774 - val_loss: 1.6587 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.43750\n",
      "Epoch 16/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6918 - acc: 0.7875 - val_loss: 1.6680 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.43750\n",
      "Epoch 17/300\n",
      "63/63 [==============================] - 100s 2s/step - loss: 0.6757 - acc: 0.7899 - val_loss: 1.6784 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.43750\n",
      "Epoch 18/300\n",
      "63/63 [==============================] - 100s 2s/step - loss: 0.6766 - acc: 0.7901 - val_loss: 1.6700 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.43750\n",
      "Epoch 19/300\n",
      "63/63 [==============================] - 100s 2s/step - loss: 0.6867 - acc: 0.8010 - val_loss: 1.6617 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.43750\n",
      "Epoch 20/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6792 - acc: 0.7936 - val_loss: 1.6596 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.43750\n",
      "Epoch 21/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6557 - acc: 0.8020 - val_loss: 1.6749 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.43750\n",
      "Epoch 22/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6534 - acc: 0.8077 - val_loss: 1.6558 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.43750\n",
      "Epoch 23/300\n",
      "63/63 [==============================] - 830s 13s/step - loss: 0.6848 - acc: 0.7800 - val_loss: 1.6620 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.43750\n",
      "Epoch 24/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6588 - acc: 0.8099 - val_loss: 1.6666 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.43750\n",
      "Epoch 25/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6575 - acc: 0.8127 - val_loss: 1.6652 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.43750\n",
      "Epoch 26/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6538 - acc: 0.8093 - val_loss: 1.6658 - val_acc: 0.4464\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.43750 to 0.44643, saving model to weights-overfit/improvement-26-0.45.hdf5\n",
      "Epoch 27/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6797 - acc: 0.7984 - val_loss: 1.6539 - val_acc: 0.4464\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.44643\n",
      "Epoch 28/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6582 - acc: 0.8087 - val_loss: 1.6508 - val_acc: 0.4464\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.44643\n",
      "Epoch 29/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6696 - acc: 0.8117 - val_loss: 1.6552 - val_acc: 0.4554\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.44643 to 0.45536, saving model to weights-overfit/improvement-29-0.46.hdf5\n",
      "Epoch 30/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6814 - acc: 0.7820 - val_loss: 1.6678 - val_acc: 0.4464\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.45536\n",
      "Epoch 31/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6524 - acc: 0.7975 - val_loss: 1.6685 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.45536\n",
      "Epoch 32/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6473 - acc: 0.8065 - val_loss: 1.6607 - val_acc: 0.4554\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.45536\n",
      "Epoch 33/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6641 - acc: 0.7889 - val_loss: 1.6704 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.45536\n",
      "Epoch 34/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6595 - acc: 0.8050 - val_loss: 1.6697 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.45536\n",
      "Epoch 35/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6509 - acc: 0.8016 - val_loss: 1.6604 - val_acc: 0.4464\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.45536\n",
      "Epoch 36/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6441 - acc: 0.8072 - val_loss: 1.6611 - val_acc: 0.4464\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.45536\n",
      "Epoch 37/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6523 - acc: 0.7930 - val_loss: 1.6553 - val_acc: 0.4464\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.45536\n",
      "Epoch 38/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6508 - acc: 0.8050 - val_loss: 1.6578 - val_acc: 0.4464\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.45536\n",
      "Epoch 39/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6621 - acc: 0.8045 - val_loss: 1.6768 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.45536\n",
      "Epoch 40/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6575 - acc: 0.7944 - val_loss: 1.6486 - val_acc: 0.4554\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.45536\n",
      "Epoch 41/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6610 - acc: 0.7949 - val_loss: 1.6509 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.45536\n",
      "Epoch 42/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6642 - acc: 0.7972 - val_loss: 1.6537 - val_acc: 0.4554\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.45536\n",
      "Epoch 43/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6508 - acc: 0.8059 - val_loss: 1.6626 - val_acc: 0.4554\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.45536\n",
      "Epoch 44/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6569 - acc: 0.8075 - val_loss: 1.6714 - val_acc: 0.4554\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.45536\n",
      "Epoch 45/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 99s 2s/step - loss: 0.6489 - acc: 0.8133 - val_loss: 1.6751 - val_acc: 0.4554\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.45536\n",
      "Epoch 46/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6422 - acc: 0.8085 - val_loss: 1.6582 - val_acc: 0.4554\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.45536\n",
      "Epoch 47/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6448 - acc: 0.8022 - val_loss: 1.6619 - val_acc: 0.4554\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.45536\n",
      "Epoch 48/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6358 - acc: 0.8054 - val_loss: 1.6622 - val_acc: 0.4554\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.45536\n",
      "Epoch 49/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6530 - acc: 0.8004 - val_loss: 1.6617 - val_acc: 0.4554\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.45536\n",
      "Epoch 50/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6534 - acc: 0.8089 - val_loss: 1.6508 - val_acc: 0.4554\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.45536\n",
      "Epoch 51/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6332 - acc: 0.8127 - val_loss: 1.6720 - val_acc: 0.4464\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.45536\n",
      "Epoch 52/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6656 - acc: 0.7838 - val_loss: 1.6779 - val_acc: 0.4464\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.45536\n",
      "Epoch 53/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6250 - acc: 0.8058 - val_loss: 1.6735 - val_acc: 0.4554\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.45536\n",
      "Epoch 54/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6589 - acc: 0.7994 - val_loss: 1.6676 - val_acc: 0.4554\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.45536\n",
      "Epoch 55/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6369 - acc: 0.7863 - val_loss: 1.6475 - val_acc: 0.4554\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.45536\n",
      "Epoch 56/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6634 - acc: 0.8010 - val_loss: 1.6747 - val_acc: 0.4554\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.45536\n",
      "Epoch 57/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6036 - acc: 0.8188 - val_loss: 1.6640 - val_acc: 0.4554\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.45536\n",
      "Epoch 58/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6370 - acc: 0.8129 - val_loss: 1.6631 - val_acc: 0.4554\n",
      "\n",
      "Epoch 00058: val_acc improved from 0.45536 to 0.45536, saving model to weights-overfit/improvement-58-0.46.hdf5\n",
      "Epoch 59/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6378 - acc: 0.7998 - val_loss: 1.6602 - val_acc: 0.4554\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.45536\n",
      "Epoch 60/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6594 - acc: 0.8059 - val_loss: 1.6697 - val_acc: 0.4554\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.45536\n",
      "Epoch 61/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6237 - acc: 0.8264 - val_loss: 1.6551 - val_acc: 0.4554\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.45536\n",
      "Epoch 62/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6374 - acc: 0.8093 - val_loss: 1.6630 - val_acc: 0.4554\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.45536\n",
      "Epoch 63/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6233 - acc: 0.7986 - val_loss: 1.6694 - val_acc: 0.4464\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.45536\n",
      "Epoch 64/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6093 - acc: 0.8192 - val_loss: 1.6645 - val_acc: 0.4464\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.45536\n",
      "Epoch 65/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6315 - acc: 0.8111 - val_loss: 1.6622 - val_acc: 0.4554\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.45536\n",
      "Epoch 66/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6261 - acc: 0.8187 - val_loss: 1.6729 - val_acc: 0.4554\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.45536\n",
      "Epoch 67/300\n",
      "63/63 [==============================] - 99s 2s/step - loss: 0.6106 - acc: 0.8317 - val_loss: 1.6732 - val_acc: 0.4554\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.45536\n",
      "Epoch 68/300\n",
      "10/63 [===>..........................] - ETA: 1:14 - loss: 0.6444 - acc: 0.8063"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-b7996912431a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m                     \u001b[0mnb_epoch\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                     \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpreprocessed_x_validation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_validation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                     callbacks = callbacks_list)\n\u001b[0m",
      "\u001b[1;32mc:\\users\\vibhu\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vibhu\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1413\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1414\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1415\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vibhu\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    211\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    212\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vibhu\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1214\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1215\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1216\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vibhu\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2664\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2666\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2667\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2668\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vibhu\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2635\u001b[0m                                 session)\n\u001b[1;32m-> 2636\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2637\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vibhu\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_generator,\n",
    "                    nb_epoch =300,\n",
    "                    validation_data = (preprocessed_x_validation, y_validation),\n",
    "                    callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open('model_new.json', 'w') as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_new.json') as file:\n",
    "    a=file.read()\n",
    "    model=model_from_json(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('weights-overfit/latest.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(Image.open('ss.png').convert('RGB').resize((299,299)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 299, 299, 3)\n"
     ]
    }
   ],
   "source": [
    "a=np.expand_dims(x, axis=0)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_p=applications.xception.preprocess_input(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.79166955, 0.09690797, 0.00515234, 0.04810159, 0.01400502,\n",
       "        0.0210832 , 0.01657484, 0.00650545]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
