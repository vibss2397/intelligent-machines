{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "# Import TensorFlow >= 1.10 and enable eager execution\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "n_critic = 5\n",
    "lr_d = 1e-4\n",
    "lr_g = 1e-4\n",
    "img_size = [64,64]\n",
    "BUFFER_SIZE = 142\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data():\n",
    "    counter=0\n",
    "    images = []\n",
    "    labels=[]\n",
    "    print('converting images...')\n",
    "    for img in os.listdir('data2'):\n",
    "        images.append(np.asarray(PIL.Image.open('data2/'+img).resize((64,64)).convert('RGB')))\n",
    "        labels.append(img.split('.')[0])\n",
    "        counter+=1\n",
    "    images = np.asarray(images).astype('float32')\n",
    "    display.clear_output(wait=True)\n",
    "    print('done converting')\n",
    "  #do something similar for the labels\n",
    "    return images    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done converting\n"
     ]
    }
   ],
   "source": [
    "images=create_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = (images - 127.5) / 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = tf.keras.layers.Dense(4*4*512, use_bias=False)\n",
    "        self.batchnorm1 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.conv1 = tf.keras.layers.Conv2DTranspose(256, (5, 5), strides=(2, 2), padding='same', use_bias=False)\n",
    "        self.batchnorm2 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.conv2 = tf.keras.layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False)\n",
    "        self.batchnorm3 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.conv3 = tf.keras.layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)\n",
    "        self.batchnorm4 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.conv5 = tf.keras.layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False)\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        x = self.fc1(x)\n",
    "        x = self.batchnorm1(x, training=training)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "\n",
    "        x = tf.reshape(x, shape=(-1, 4, 4, 512))\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchnorm2(x, training=training)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.batchnorm3(x, training=training)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.batchnorm4(x, training=training)\n",
    "        x = tf.nn.leaky_relu(x) \n",
    "\n",
    "\n",
    "        x = tf.nn.tanh(self.conv5(x))  \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Critic, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same')\n",
    "        \n",
    "        self.conv2= tf.keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same')\n",
    "        \n",
    "        self.conv3= tf.keras.layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same')\n",
    "        \n",
    "        self.conv4= tf.keras.layers.Conv2D(512, (5, 5), strides=(2, 2), padding='same')\n",
    "        \n",
    "        self.dropout = tf.keras.layers.Dropout(0.3)\n",
    "        \n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        \n",
    "        self.fc1 = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, x, training = True):\n",
    "        x = tf.nn.leaky_relu(self.conv1(x))\n",
    "        x = self.dropout(x, training=training)\n",
    "        \n",
    "        x = tf.nn.leaky_relu(self.conv2(x))\n",
    "        x = self.dropout(x, training=training)\n",
    "        \n",
    "        x = tf.nn.leaky_relu(self.conv3(x))\n",
    "        x = self.dropout(x, training=training)\n",
    "        \n",
    "        x = tf.nn.leaky_relu(self.conv4(x))\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "critic = Critic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.call = tf.contrib.eager.defun(generator.call)\n",
    "critic.call = tf.contrib.eager.defun(critic.call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_critic_loss(real_output, generated_output):\n",
    "    loss = tf.reduce_mean(real_output) - tf.reduce_mean(generated_output)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator_loss(generated_output):\n",
    "    return tf.reduce_mean(generated_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_optimizer = tf.train.AdamOptimizer(lr_d)\n",
    "generator_optimizer = tf.train.AdamOptimizer(lr_g)\n",
    "\n",
    "# weight clipping for wgan\n",
    "discriminator_optimizer_clipped = tf.contrib.gan.features.clip_variables(discriminator_optimizer, critic.variables, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = 'checkpoint-wgan/'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator = generator,\n",
    "                                 critic = critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 2000\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# keeping the random vector constant for generation (prediction) so\n",
    "# it will be easier to see the improvement of the gan.\n",
    "random_vector_for_generation = tf.random_normal([num_examples_to_generate,\n",
    "                                                 noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch):\n",
    "  # make sure the training parameter is set to False because we\n",
    "  # don't want to train the batchnorm layer when doing inference.\n",
    "    predictions = model(random_vector_for_generation, training=False)\n",
    "    e2=predictions*127.5+127.5\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "        \n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(np.uint8(e2[i]))\n",
    "        plt.axis('off')\n",
    "        \n",
    "    plt.savefig('generated/wgan-gp_image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs, noise_dim):  \n",
    "    iteration=1\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "    \n",
    "        for images in dataset:\n",
    "            if((iteration) % 6 != 0):\n",
    "                # generating noise from a uniform distribution\n",
    "                noise = tf.random_normal([BATCH_SIZE, noise_dim])\n",
    "      \n",
    "                with tf.GradientTape() as critic_tape, tf.GradientTape() as tape:\n",
    "                    generated_images = generator(noise, training=True)\n",
    "                    \n",
    "                    real_output = critic(images, training=True)\n",
    "                    generated_output = critic(generated_images, training=True)\n",
    "                    critic_loss = get_critic_loss(real_output, generated_output)\n",
    "                    \n",
    "#                     # calculating gradient penalty term, still experimental\n",
    "#                     with tf.GradientTape() as tape:\n",
    "                    epsilon = tf.random_uniform([], 0, 1)\n",
    "                    xhat = epsilon*images + (1-epsilon)*generated_images\n",
    "                    tape.watch(xhat)\n",
    "                    dhat = critic(xhat, training=True)\n",
    "                    dhat_grad = tape.gradient(dhat, xhat)\n",
    "                    slopes = tf.sqrt(tf.reduce_sum(tf.square(dhat2), reduction_indices=[1]))\n",
    "                    gradient_penalty = 10*tf.reduce_mean((slopes-1.0)**2)\n",
    "                    critic_loss += gradient_penalty\n",
    "                    \n",
    "                gradients_of_critic = critic_tape.gradient(critic_loss, critic.variables)\n",
    "                discriminator_optimizer_clipped.apply_gradients(zip(gradients_of_critic, critic.variables))\n",
    "                iteration+=1\n",
    "            else:\n",
    "                with tf.GradientTape() as generator_tape:\n",
    "                    noise = tf.random_normal([BATCH_SIZE, noise_dim])\n",
    "                    generated_images2 = generator(noise, training=True)\n",
    "                    gen_loss = get_generator_loss(generated_images2)\n",
    "                \n",
    "                gradients_of_generator = generator_tape.gradient(gen_loss, generator.variables)\n",
    "                generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.variables))\n",
    "                iteration+=1\n",
    "      \n",
    "        if epoch % 1 == 0:\n",
    "            display.clear_output(wait=True)\n",
    "            generate_and_save_images(generator,epoch + 1)\n",
    "    \n",
    "    # saving (checkpoint) the model every 15 epochs\n",
    "        if (epoch + 1) % 15 == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "    \n",
    "        print ('Time taken for epoch {} is {} sec'.format(epoch + 1,\n",
    "                                                      time.time()-start))\n",
    "  # generating after the final epoch\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(train_dataset, EPOCHS, noise_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
